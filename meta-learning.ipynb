{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1872300,"sourceType":"datasetVersion","datasetId":1114664}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\nfile_path = \"/kaggle/input/movielens-1m-dataset/ratings.dat\"\n\ncolumns = ['user_id', 'item_id', 'rating', 'timestamp']\n\n# Load dataset\ndf = pd.read_csv(file_path, sep='::', names=columns, engine='python')\n\n# Display head and shape\nprint(df.head())\nprint(f\"Dataset shape: {df.shape}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:18:08.602891Z","iopub.execute_input":"2025-01-10T21:18:08.603192Z","iopub.status.idle":"2025-01-10T21:18:14.558729Z","shell.execute_reply.started":"2025-01-10T21:18:08.603159Z","shell.execute_reply":"2025-01-10T21:18:14.557615Z"}},"outputs":[{"name":"stdout","text":"   user_id  item_id  rating  timestamp\n0        1     1193       5  978300760\n1        1      661       3  978302109\n2        1      914       3  978301968\n3        1     3408       4  978300275\n4        1     2355       5  978824291\nDataset shape: (1000209, 4)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Sort by user_id and timestamp\ndf_sorted = df.sort_values(by=['user_id', 'timestamp']).reset_index(drop=True)\n\n# Save the sorted data (optional, saved in Kaggle working directory)\nsorted_file_path = \"/kaggle/working/sorted_ratings.csv\"\ndf_sorted.to_csv(sorted_file_path, index=False)\n\n# Confirm the sorting\nprint(df_sorted.head())\nprint(f\"Sorted dataset saved to: {sorted_file_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:18:14.559713Z","iopub.execute_input":"2025-01-10T21:18:14.560098Z","iopub.status.idle":"2025-01-10T21:18:16.074331Z","shell.execute_reply.started":"2025-01-10T21:18:14.560041Z","shell.execute_reply":"2025-01-10T21:18:16.073304Z"}},"outputs":[{"name":"stdout","text":"   user_id  item_id  rating  timestamp\n0        1     3186       4  978300019\n1        1     1270       5  978300055\n2        1     1721       4  978300055\n3        1     1022       5  978300055\n4        1     2340       3  978300103\nSorted dataset saved to: /kaggle/working/sorted_ratings.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\n\n# Get unique users\nunique_users = df_sorted['user_id'].unique()\n\n# Split users into training and test sets (e.g., 80% for training, 20% for testing)\nnp.random.seed(42)\ntest_user_count = int(0.2 * len(unique_users))  # 20% users for testing\ntest_users = np.random.choice(unique_users, size=test_user_count, replace=False)\ntrain_users = np.setdiff1d(unique_users, test_users)\n\ntrain_data = df_sorted[df_sorted['user_id'].isin(train_users)]\ntest_data = df_sorted[df_sorted['user_id'].isin(test_users)]\n\ntrain_file_path = \"/kaggle/working/train_ratings.csv\"\ntest_file_path = \"/kaggle/working/test_ratings.csv\"\n\ntrain_data.to_csv(train_file_path, index=False)\ntest_data.to_csv(test_file_path, index=False)\n\nprint(f\"Training data shape: {train_data.shape}\")\nprint(f\"Test data shape: {test_data.shape}\")\nprint(f\"Training data saved to: {train_file_path}\")\nprint(f\"Test data saved to: {test_file_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:18:16.075540Z","iopub.execute_input":"2025-01-10T21:18:16.075906Z","iopub.status.idle":"2025-01-10T21:18:17.375601Z","shell.execute_reply.started":"2025-01-10T21:18:16.075868Z","shell.execute_reply":"2025-01-10T21:18:17.374582Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (808218, 4)\nTest data shape: (191991, 4)\nTraining data saved to: /kaggle/working/train_ratings.csv\nTest data saved to: /kaggle/working/test_ratings.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from surprise import Dataset, Reader, SVD\nfrom surprise.model_selection import train_test_split\nfrom surprise import accuracy\n\n# Load the training data\ntrain_file_path = r\"/kaggle/working/train_ratings.csv\"\ntrain_data = pd.read_csv(train_file_path)\n\nreader = Reader(rating_scale=(1, 5))  # Ratings range in MovieLens is 1-5\ndata = Dataset.load_from_df(train_data[['user_id', 'item_id', 'rating']], reader)\n\ntrainset, valset = train_test_split(data, test_size=0.2, random_state=42)\n\n# Train an SVD model\nsvd_model = SVD()\nsvd_model.fit(trainset)\n\n# Evaluate the model on the validation set\npredictions = svd_model.test(valset)\nrmse = accuracy.rmse(predictions)\nprint(f\"Validation RMSE: {rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:19:06.466522Z","iopub.execute_input":"2025-01-10T21:19:06.466887Z","iopub.status.idle":"2025-01-10T21:19:22.138437Z","shell.execute_reply.started":"2025-01-10T21:19:06.466861Z","shell.execute_reply":"2025-01-10T21:19:22.137149Z"}},"outputs":[{"name":"stdout","text":"RMSE: 0.8794\nValidation RMSE: 0.8794330740426275\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from surprise import SVD, Dataset, Reader\nfrom sklearn.metrics import mean_squared_error\nimport pandas as pd\nimport numpy as np\n\ndef prepare_data_for_cold_start(test_data, n_known=5):\n    users = test_data['user_id'].unique()\n    cold_start_users = []\n    for user in users:\n        user_data = test_data[test_data['user_id'] == user]\n        if len(user_data) > n_known:\n            cold_start_users.append(user)\n    \n    cold_start_data = []\n    for user in cold_start_users:\n        user_data = test_data[test_data['user_id'] == user]\n        known_ratings = user_data.iloc[:n_known]\n        unknown_ratings = user_data.iloc[n_known:]\n        cold_start_data.append((known_ratings, unknown_ratings))\n    \n    return cold_start_data\n\ndef evaluate_svd_on_cold_start(svd_model, cold_start_data, num_items=1266):\n    all_rmse = []\n    \n    for known_ratings, unknown_ratings in cold_start_data:\n        # Convert known ratings to Surprise dataset format\n        reader = Reader(rating_scale=(1, 5))  # Adjust rating scale if necessary\n        data = Dataset.load_from_df(known_ratings[['user_id', 'item_id', 'rating']], reader)\n        trainset = data.build_full_trainset()\n        \n        # Train the SVD model using Surprise\n        svd_model.fit(trainset)\n        \n        # Predict ratings for the unknown items\n        predicted_ratings = []\n        actual_ratings = []\n        \n        for _, row in unknown_ratings.iterrows():\n            pred = svd_model.predict(row['user_id'], row['item_id'])\n            predicted_ratings.append(pred.est)\n            actual_ratings.append(row['rating'])\n        \n        # Calculate RMSE for the current user\n        mse = mean_squared_error(actual_ratings, predicted_ratings)\n        rmse = np.sqrt(mse)\n        all_rmse.append(rmse)\n    \n    # Calculate overall RMSE for all cold-start users\n    overall_rmse = np.mean(all_rmse)\n    return overall_rmse\n\n# Load the test data and split it into cold-start data\ntest_file_path = '/kaggle/working/test_ratings.csv'  # Replace with actual file path\ntest_data = pd.read_csv(test_file_path)\ncold_start_data = prepare_data_for_cold_start(test_data, n_known=5)\n\n# Initialize the SVD model from Surprise\nsvd_model = SVD()\n\n# Evaluate the SVD model on the cold-start task\nsvd_model_rmse = evaluate_svd_on_cold_start(svd_model, cold_start_data)\n\nprint(f\"SVD Model RMSE: {svd_model_rmse}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:19:33.195865Z","iopub.execute_input":"2025-01-10T21:19:33.196260Z","iopub.status.idle":"2025-01-10T21:19:46.259407Z","shell.execute_reply.started":"2025-01-10T21:19:33.196233Z","shell.execute_reply":"2025-01-10T21:19:46.258318Z"}},"outputs":[{"name":"stdout","text":"SVD Model RMSE: 1.1533355987456415\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n\n# Ensure the padding works correctly\ndef prepare_meta_learning_data(df, n_known=5, pad_value=0):\n    \"\"\"\n    Prepare data for the meta-learning model with padding.\n    \n    Parameters:\n    - df: DataFrame with user_id, item_id, rating.\n    - n_known: Number of known ratings to provide as input.\n    - pad_value: Value to pad the sequences for the unknown ratings.\n    \n    Returns:\n    - meta_train_X: Features for training (known ratings).\n    - meta_train_y: Targets for training (unknown ratings).\n    \"\"\"\n    meta_train_X = []\n    meta_train_y = []\n\n    # Group data by user_id\n    grouped = df.groupby('user_id')\n\n    max_unknown_ratings = 0\n\n    # First, determine the maximum number of unknown ratings per user for padding\n    for user_id, group in grouped:\n        group = group.sort_values(by='timestamp')\n        if len(group) <= n_known:\n            continue\n        unknown_data = group.iloc[n_known:]\n        max_unknown_ratings = max(max_unknown_ratings, len(unknown_data))\n\n    # Now, prepare the features and targets\n    for user_id, group in grouped:\n        group = group.sort_values(by='timestamp')\n        if len(group) <= n_known:\n            continue\n\n        # Split known and unknown ratings\n        known_data = group.iloc[:n_known]\n        unknown_data = group.iloc[n_known:]\n\n        # Prepare input (known ratings) and output (unknown ratings)\n        known_ratings = known_data['rating'].values\n        unknown_ratings = unknown_data['rating'].values\n\n        # Pad the sequences to the max_unknown_ratings\n        padded_known = np.pad(known_ratings, (0, n_known - len(known_ratings)), mode='constant', constant_values=pad_value)\n        padded_unknown = np.pad(unknown_ratings, (0, max_unknown_ratings - len(unknown_ratings)), mode='constant', constant_values=pad_value)\n\n        meta_train_X.append(padded_known)\n        meta_train_y.append(padded_unknown)\n\n    return np.array(meta_train_X), np.array(meta_train_y)\n\n# Prepare the data\nmeta_train_X, meta_train_y = prepare_meta_learning_data(train_data, n_known=5)\nmeta_test_X, meta_test_y = prepare_meta_learning_data(test_data, n_known=5)\n\nprint(f\"Training data shape: X={meta_train_X.shape}, y={meta_train_y.shape}\")\nprint(f\"Testing data shape: X={meta_test_X.shape}, y={meta_test_y.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:20:07.983112Z","iopub.execute_input":"2025-01-10T21:20:07.983513Z","iopub.status.idle":"2025-01-10T21:20:12.229197Z","shell.execute_reply.started":"2025-01-10T21:20:07.983481Z","shell.execute_reply":"2025-01-10T21:20:12.227588Z"}},"outputs":[{"name":"stdout","text":"Training data shape: X=(4832, 5), y=(4832, 2309)\nTesting data shape: X=(1208, 5), y=(1208, 1266)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\n# Adjust target shape if necessary\ndef ensure_target_shape(meta_train_y, target_shape=(1208, 1266)):\n    if meta_train_y.shape[1] != target_shape[1]:\n        meta_train_y = meta_train_y[:, :target_shape[1]]  # Adjust if needed\n    return meta_train_y\n\n# Model Creation (adjusted to target shape of 1266)\ndef create_meta_model(n_known=5, n_unknown=1266, n_hidden=64):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(n_known,)),  # Input layer with the correct shape (5 known ratings)\n        tf.keras.layers.Dense(n_hidden, activation='relu'),\n        tf.keras.layers.Dense(n_hidden, activation='relu'),\n        tf.keras.layers.Dense(n_unknown, activation='linear')  # Predict only the unknown ratings\n    ])\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model\n\n# Ensure target data is correctly shaped\nmeta_train_y = ensure_target_shape(meta_train_y, target_shape=(1208, 1266))\nmeta_test_y = ensure_target_shape(meta_test_y, target_shape=(1208, 1266))\n\n# Create the model with correct output size (1266)\nmeta_model = create_meta_model(n_known=5, n_unknown=1266)\n\n# Train the model\nmeta_model.fit(\n    meta_train_X, meta_train_y,\n    validation_split=0.2,\n    epochs=10,\n    batch_size=32\n)\n\n# Evaluate the model\ntest_loss, test_mae = meta_model.evaluate(meta_test_X, meta_test_y)\nprint(f\"Test Loss (MSE): {test_loss}\")\nprint(f\"Test MAE: {test_mae}\")\n\n# Predict ratings for unseen users\nmeta_predictions = meta_model.predict(meta_test_X)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:20:23.558975Z","iopub.execute_input":"2025-01-10T21:20:23.559346Z","iopub.status.idle":"2025-01-10T21:20:39.497227Z","shell.execute_reply.started":"2025-01-10T21:20:23.559320Z","shell.execute_reply":"2025-01-10T21:20:39.496262Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4186 - mae: 0.5669 - val_loss: 0.9583 - val_mae: 0.5102\nEpoch 2/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0448 - mae: 0.5288 - val_loss: 0.9584 - val_mae: 0.5432\nEpoch 3/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0189 - mae: 0.5247 - val_loss: 0.9549 - val_mae: 0.5128\nEpoch 4/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9912 - mae: 0.5008 - val_loss: 0.9594 - val_mae: 0.5305\nEpoch 5/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0406 - mae: 0.5307 - val_loss: 0.9576 - val_mae: 0.5337\nEpoch 6/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0082 - mae: 0.5185 - val_loss: 0.9485 - val_mae: 0.4762\nEpoch 7/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0222 - mae: 0.5163 - val_loss: 0.9518 - val_mae: 0.5061\nEpoch 8/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0296 - mae: 0.5264 - val_loss: 0.9495 - val_mae: 0.4855\nEpoch 9/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9819 - mae: 0.5009 - val_loss: 0.9477 - val_mae: 0.4859\nEpoch 10/10\n\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0126 - mae: 0.5139 - val_loss: 0.9478 - val_mae: 0.5102\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9341 - mae: 0.5111\nTest Loss (MSE): 0.9485242366790771\nTest MAE: 0.5129644274711609\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Compare predicted ratings with actual ratings for evaluation\nfrom sklearn.metrics import mean_squared_error\nrmse = np.sqrt(mean_squared_error(meta_test_y.flatten(), meta_predictions.flatten()))\nprint(f\"Meta-Learning Model RMSE: {rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:20:39.498716Z","iopub.execute_input":"2025-01-10T21:20:39.499459Z","iopub.status.idle":"2025-01-10T21:20:39.520314Z","shell.execute_reply.started":"2025-01-10T21:20:39.499428Z","shell.execute_reply":"2025-01-10T21:20:39.519345Z"}},"outputs":[{"name":"stdout","text":"Meta-Learning Model RMSE: 0.9739220481294046\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Comparing improvement\nold_rmse = 1.1533355987456415\nnew_rmse = 0.9739220481294046\n\nimprovement = ((old_rmse - new_rmse) / old_rmse) * 100\nprint(f\"Percentage Improvement: {improvement:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:22:15.798911Z","iopub.execute_input":"2025-01-10T21:22:15.799274Z","iopub.status.idle":"2025-01-10T21:22:15.805453Z","shell.execute_reply.started":"2025-01-10T21:22:15.799250Z","shell.execute_reply":"2025-01-10T21:22:15.804205Z"}},"outputs":[{"name":"stdout","text":"Percentage Improvement: 15.56%\n","output_type":"stream"}],"execution_count":10}]}